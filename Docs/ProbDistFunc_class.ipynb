{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProbDistFunc_class.py\n",
    "\n",
    "This class takes care of the probability distribution data and methods to manipulate it\n",
    "\n",
    "### Methods\n",
    "\n",
    "**`ProbDistFunc.pdf_config(self, paramvals)`**  \n",
    "This method sets up (possibly multidimensional) arrays to represent the probability distribution function (pdf) and initializes them to a uniform state.  Two such arrays are set up, one to represent the probability distribution, and one for the `log()` of the probability distribution.  \n",
    "\n",
    " - `paramvals` is a tuple of arrays, each containing the allowed range of a parameter.  The number of arrays (i.e. the number of parameters) determines the dimensionality of the pdf array and the size of the arrays determines the size of the pdf.  Example: if paramvals contains two arrays with 15 and 38 values respectively, the pdf will be a 15 $\\times$ 38 2D array.\n",
    "\n",
    "**`ProbDistFunc.set_pdf(self, flat=False, probvalarrays=[], pdf=[], lnpdf=[])`**  \n",
    "This method provides four different ways to set the values of the probability distribution function.  \n",
    "\n",
    " - `flat` if True, the probability distribution will be reinitialized to a constant value, default = `False`,\n",
    " - `probvalarrays` if not empty, a tuple of 1D arrays representing the a prior distribution for each parameter.  The new pdf will be constructed as the outer product of these arrays.\n",
    " - `pdf` if not empty, a multidimensional array with dimensions corresponding to the dimensions determined during the `pdf_config()` initialization. The `lnPDF` values are calculated from the specified `PDF` values.\n",
    " - `lnpdf` same as `pdf` but with the `lnPDF` specified and `pdf` calculated.\n",
    "\n",
    "\n",
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Bob McMichael'\n",
    "\n",
    "import numpy.ma as ma\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ProbDistFunc:\n",
    "    \"\"\"\n",
    "    A probability distribution function class\n",
    "    variables:\n",
    "        lnPDF -- an N-dimensional array, one axis for each variable parameter\n",
    "            contains nat.log of the probability, not normalized\n",
    "        shape -- tuple describing dimensions of pdf\n",
    "        paramspace -- a tuple of arrays and constants intended for iterating over all of parameter space\n",
    "        paramisarray -- which parameters are arrays, i.e. variables\n",
    "    methods:\n",
    "        __init__ -- determines the pdf's shape from lists/arrays of possible parameter values\n",
    "             -- creates paramspace for model evaluation over all parameter space\n",
    "             -- determines which parameters are variabls\n",
    "        set_pdf -- initial value for the pdf\n",
    "        update_pdf --  updates the lnPDF by (typically) adding a lnlikelyhood\n",
    "        markov_draws -- generates an array of parameter sets using a random walk in the pdf.\n",
    "        entropy  -- calculate the entropy of the pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.Ndraws=200\n",
    "\n",
    "    def pdf_config(self, paramvals):\n",
    "        # paramvals is expected to be a tuple of arrays containing all possible parameter values\n",
    "        # nuisance is\n",
    "        self.paramvals = paramvals\n",
    "        # determine the shape of the PDF required to accommodate all of the paramvals\n",
    "        shape = ()\n",
    "        for paramarray in paramvals:\n",
    "            shape += (len(paramarray),)\n",
    "        self.pdfshape = shape\n",
    "        self.pdfdims = len(self.pdfshape)\n",
    "        # create arrays to hold the lnPDF and PDF\n",
    "        # initialized to a flat probability distribution\n",
    "        self.lnPDF = np.zeros(self.pdfshape)\n",
    "        self.PDF = np.ones(self.pdfshape)\n",
    "\n",
    "    def set_pdf(self, flat=False, probvalarrays=[], pdf=[], lnpdf=[]):\n",
    "        # set the pdf with some initial guess or restore a saved version\n",
    "        done = 0\n",
    "        if flat:\n",
    "            self.lnPDF = np.zeros(self.pdfshape)\n",
    "            self.PDF = np.ones(self.pdfshape)\n",
    "            done += 1\n",
    "        if probvalarrays:\n",
    "            # Used when the user initializes with a 1-D array of probabilities for each variable parameter\n",
    "            self.PDF = self.__multiply_probs(probvalarrays)\n",
    "            self.lnPDF = np.log(self.PDF)\n",
    "            done += 1\n",
    "        if pdf:\n",
    "            if np.array(pdf).shape != self.pdfshape:\n",
    "                pass  # raise an error - pdf shape doesn't fit parameter values\n",
    "            else:\n",
    "                self.PDF = pdf\n",
    "                self.lnPDF = np.log(pdf)\n",
    "                done += 1\n",
    "        if lnpdf:\n",
    "            if np.array(pdf).shape != self.pdfshape:\n",
    "                pass  # raise an error - pdf shape doesn't fit parameter values\n",
    "            else:\n",
    "                self.lnPDF = lnpdf\n",
    "                self.PDF = np.exp(lnpdf)\n",
    "                done += 1\n",
    "        if done != 1:  # the pdf should be set exactly once\n",
    "            pass  # raise an error\n",
    "\n",
    "    def add_lnpdf(self, lnlikelihood):\n",
    "        # add the log of likelihood of a measurement to update the PDF\n",
    "        self.lnPDF += lnlikelihood\n",
    "        # pseudo-normalize to max lnPDF=0 --> max PDF = 1\n",
    "        self.lnPDF -= self.lnPDF.max()\n",
    "        self.PDF = np.exp(self.lnPDF)\n",
    "\n",
    "    def multiply_pdf(self, likelihood):\n",
    "        # multiply by another\n",
    "        self.lnPDF += np.ln(likelihood)\n",
    "        # pseudo-normalize to max lnPDF=0 --> max PDF = 1\n",
    "        self.lnPDF -= self.lnPDF.max()\n",
    "        self.PDF = np.exp(self.lnPDF)\n",
    "\n",
    "    def markov_draws(self):\n",
    "        \"\"\"\n",
    "        produce a number of samples from a probability distribution function\n",
    "        using a Markov chain process\n",
    "        :param n_draws:   the number of samples to generate\n",
    "        :param n_burn:    desired number of \"pre-randomizing\" moves\n",
    "        :return: a list of parameter combinations\n",
    "        \"\"\"\n",
    "\n",
    "        return self.__markov_chain_gen_ND(self.Ndraws, self.Ndraws)\n",
    "\n",
    "    def max_params(self):\n",
    "        \"\"\"\n",
    "        find the parameters corresponding to the max probability\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # argmax returns the index of the maximum of the flattened version of self.PDF\n",
    "        maxindex = np.argmax(self.PDF)\n",
    "        # calculate indices of the unflattened version\n",
    "        ix = np.unravel_index(maxindex, self.pdfshape)\n",
    "        # list comprehension to get the parameter values corresponding to the indices\n",
    "        maxpars = [p[i] for p, i in zip(self.paramvals, ix)]\n",
    "        # convert to tuple because our models expect tuples.\n",
    "        print(maxpars)\n",
    "        return tuple(maxpars)\n",
    "\n",
    "    def get_PDF(self, denuisance=(), normalize=True):\n",
    "        \"\"\"\n",
    "        packaging & polishing the PDF\n",
    "        Integrate over nuisance parameters, normalize and return the resulting pdf.\n",
    "        :param denuisance:   tuple identifying parameters to be integrated out of self.PDF (default none)\n",
    "        :param normalize:  Boolean to normalize sum=1 (default yes)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.__normalize(self.__denuisance_pdf(denuisance), normalize)\n",
    "\n",
    "    def get_std(self, paraxis):\n",
    "        \"\"\"\n",
    "        compute the standard deviation of the PDF collapsed down to 1 axis\n",
    "        :param paraxis: the axis of the pdf corresponding to the vaiable of interest.\n",
    "        :return: standard deviation  (float)\n",
    "        \"\"\"\n",
    "        # We need a list of axes to sum, i.e. all axes _except_ for the requested paraxis,\n",
    "        # all axes\n",
    "        axes = list(np.arange(self.pdfdims))\n",
    "        # remove the parameter axis\n",
    "        del axes[paraxis]\n",
    "\n",
    "        # get the collapsed pdf\n",
    "        oneDpdf = self.get_PDF(denuisance=axes, normalize=True)\n",
    "        # and the corresponding parameter values\n",
    "        oneParam = np.array(self.paramvals[paraxis])\n",
    "\n",
    "        # calculate the standard deviation using sums\n",
    "        pbar = np.sum(oneDpdf * oneParam)\n",
    "        psquare = np.sum(oneDpdf * oneParam **2)\n",
    "        ssquare = psquare - pbar**2\n",
    "        return np.sqrt(ssquare)\n",
    "\n",
    "    def entropy(self):\n",
    "        return self.__calculate_discrete_Entropy(self.PDF)\n",
    "\n",
    "    \"\"\"The nitty-gritty details, in private methods\"\"\"\n",
    "\n",
    "    def __denuisance_pdf(self, denuisance=()):\n",
    "        \"\"\"\n",
    "        take the PDF and sum over axes indicated by the nuisance tuple\n",
    "        then reshape\n",
    "        :param denuisance:  a tuple indicating axes to be 'integrated' out\n",
    "        :return: nparray with collapsed, de-nuisanceified pdf\n",
    "        \"\"\"\n",
    "        if denuisance:\n",
    "            return np.sum(self.PDF, axis=tuple(denuisance))\n",
    "        else:\n",
    "            # If denuisance = False (default), skip the procedure and return PDF\n",
    "            return self.PDF\n",
    "\n",
    "    def __normalize(self, a_pdf, normalize=True):\n",
    "        \"\"\"\n",
    "        Normalize the input array\n",
    "        :param a_pdf:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if normalize:\n",
    "            return a_pdf / a_pdf.sum()\n",
    "        else:\n",
    "            return a_pdf\n",
    "\n",
    "    def __multiply_probs(self, probvals):\n",
    "        # Used when the user initializes with a 1-D array of probabilities for each variable parameter\n",
    "        # sift out just the variables\n",
    "\n",
    "        meshes = list(np.meshgrid(*probvals, indexing='ij'))\n",
    "\n",
    "        # probability arrays must have same shape and order as parameter arrays\n",
    "        if meshes[0].shape != self.pdfshape:\n",
    "            pass  # raise an error -\n",
    "\n",
    "        # multiply all of the probabilities together\n",
    "        pdf = np.ones(self.pdfshape)\n",
    "        for mesh in meshes:\n",
    "            pdf *= mesh\n",
    "        return pdf\n",
    "\n",
    "    def __randdraw(self, r, dist):\n",
    "        \"\"\"\n",
    "        Draw a random index value from a 1-D distribution\n",
    "        :param r: a random number btw 0:1\n",
    "        :param dist:  a distribution \"function\" as a 1-D array, maybe unnormalized\n",
    "        :return: randomly drawn index from dist\n",
    "        \"\"\"\n",
    "        # the strategy is to compare a random number with the running integral (cumulative sum) of the pdf\n",
    "        cumdist = np.cumsum(dist)\n",
    "        # rather than normalize the whole distribution, we'll just scale up the random numbers\n",
    "        # so that they span [0:cumdist[-1]).  the last value of cumdist is the \"integral\" of the dist.\n",
    "        rscaled = r * cumdist[-1]\n",
    "\n",
    "        # Next, find the index where cumdist > rscaled\n",
    "        bigger = np.array(np.nonzero(cumdist > rscaled))\n",
    "        # nonzero returns a tuple with the array of indices in the first element\n",
    "        if bigger.shape[1] == 0:\n",
    "            return len(cumdist) - 1\n",
    "        else:\n",
    "            return bigger[0][0]\n",
    "\n",
    "    def __markov_chain_gen_ND(self, n_draws, n_burn=100):\n",
    "        \"\"\"\n",
    "        produce a number of samples from a probability distribution function\n",
    "        using a Markov chain process\n",
    "        :param pdf:         an N-dimensional pdf\n",
    "        :param n_draws:     the number of samples to generate\n",
    "        :param n_burn:    desired number of \"pre-randomizing\" moves\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # Getting to know youuuu, getting to know all about youuuu!\n",
    "        # learn about the pdf\n",
    "        ndims = len(self.pdfshape)\n",
    "\n",
    "        # generate a random location to start\n",
    "        location = []\n",
    "        for i, paramarray in enumerate(self.paramvals):\n",
    "            # append a random position along an axis, but only for variable parameters\n",
    "            location.append(np.random.randint(len(paramarray)))\n",
    "\n",
    "        # while True:\n",
    "        # The initial burn-in: n_burn full Markov moves\n",
    "        # A full move here is one where the position in the pdf changes in all directions\\\n",
    "        # first, a collection of random numbers to draw from\n",
    "        rand_bucket = np.random.random((n_burn, ndims))\n",
    "\n",
    "        # making n_burn full moves\n",
    "        for i in np.arange(n_burn):\n",
    "            # making one step along each axis\n",
    "            for axis in np.arange(ndims):\n",
    "                # substitute an ellipsis as an index in the location to get the probabilities along one axis\n",
    "                # it's a python thing.\n",
    "                location[axis] = ...\n",
    "                # pdf[location] will now return a 1D array that we interpret as a pdf, and we make a random draw\n",
    "                # for the new location along the axis\n",
    "                location[axis] = self.__randdraw(rand_bucket[i, axis], self.PDF[location])\n",
    "\n",
    "        # Now that the Markov chain has been initialized, we move to generating the actual draws from the pdf\n",
    "        # each full move generates Ndims draws, so we'll need this many moves.\n",
    "        nmoves = int(n_draws / ndims) + 1\n",
    "        # a stash of random numbers\n",
    "        rand_pail = np.random.random((nmoves, ndims))\n",
    "        # a place for the draws to go, perhaps slightly more spaces than needed for n_draws\n",
    "\n",
    "        draws = np.zeros((nmoves * ndims, ndims), dtype='int')\n",
    "\n",
    "        i_draw = 0  # a counter\n",
    "        # make the full moves\n",
    "        for i in np.arange(nmoves):\n",
    "            # make one step along each axis as before\n",
    "            for axis in np.arange(ndims):\n",
    "                location[axis] = ...\n",
    "                location[axis] = self.__randdraw(rand_pail[i, axis], self.PDF[location])\n",
    "                # store the new location\n",
    "                draws[i_draw, :] = np.array(location)\n",
    "                i_draw += 1\n",
    "\n",
    "        # all done with our random walk\n",
    "        # so now we have a bunch of draws in terms of index location in the PDF array.\n",
    "        # But, we really need the actual parameter values\n",
    "        paramdraws = np.zeros((n_draws, ndims))\n",
    "        # stepping through the required number of draws\n",
    "        for i, location in enumerate(draws[:n_draws]):\n",
    "            # store a the parameter value\n",
    "            for j, param in enumerate(self.paramvals):\n",
    "                paramdraws[i, j] = param[location[j]]\n",
    "\n",
    "        return paramdraws\n",
    "\n",
    "    def __calculate_discrete_Entropy(self, a_pdf):\n",
    "        \"\"\"\n",
    "        Calculate the entropy of a discrete distribution.\n",
    "        :param distro: an array of probability density possibly unnormalized\n",
    "        :return: sum of x * log2(x)\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \"There's an app for that\" --> scipy.stats.entropy does almost the same thing, but without flattening\n",
    "        and also offering the Kullback-Leibler divergence and offering different log bases.\n",
    "        \"\"\"\n",
    "        # flatten the distro array to 1D - we're just going to add things up anyways\n",
    "        # Clean out the zeros (anything less than 1e-100) because zeros cause problems and\n",
    "        # contribute nothing to either normalization or entropy integrals\n",
    "        maskeddist = ma.masked_less(a_pdf.flatten(), 1e-100).compressed()\n",
    "        # normalization\n",
    "        norm = maskeddist.sum()\n",
    "        # the obvious thing would be to divide the whole maskeddist array by norm.\n",
    "        # However, we can avoid an array operation by handling the norm separately\n",
    "        #   Sum( P/n * ln (P/n) )\n",
    "        # = Sum( P*ln(P) )/n - Sum(P)*ln(n)/n\n",
    "        # = Sum( P*ln(P) )/n - ln(n)\n",
    "        # entropy integrand\n",
    "        integrand = maskeddist * np.log2(maskeddist)\n",
    "        return -integrand.sum() / norm + np.log2(norm)\n",
    "\n",
    "\n",
    "def self_test():\n",
    "    xmin, xmax, ymin, ymax = (-1, 1, -2, 2)\n",
    "    extent = [xmin, xmax, ymin, ymax]\n",
    "\n",
    "    xparam = np.linspace(xmin, xmax, 101)\n",
    "    yparam = np.linspace(ymin, ymax, 201)\n",
    "\n",
    "    #mypdf = ProbDistFunc((xparam, yparam))\n",
    "    mypdf = ProbDistFunc()\n",
    "    mypdf.pdf_config((xparam,yparam))\n",
    "\n",
    "    print('default mypdf.shape = {}'.format(mypdf.pdfshape))\n",
    "    print('default mypdf.lnPDF = {}'.format(mypdf.lnPDF))\n",
    "    print('default mypdf.PDF = {}'.format(mypdf.PDF))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.subplot(221)\n",
    "    plt.title('default')\n",
    "    plt.imshow(mypdf.PDF.T, extent=extent, cmap='cubehelix', aspect='auto')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(222)\n",
    "    plt.title('probvalarrays')\n",
    "    xprobs = 1 - xparam * xparam / 1.1\n",
    "    yprobs = 1 - yparam * yparam / 8\n",
    "    mypdf.set_pdf(probvalarrays=(xprobs, yprobs))\n",
    "    plt.imshow(mypdf.PDF.T, extent=extent, cmap='cubehelix', aspect='auto')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(223)\n",
    "    plt.title('exp')\n",
    "    XX, YY = np.meshgrid(xparam, yparam, indexing='ij')\n",
    "    print('XX.shape = {}'.format(XX.shape))\n",
    "    mypdf.set_pdf(pdf=np.exp(-(XX * XX + YY * YY + XX * YY) * 5))\n",
    "    plt.imshow(mypdf.PDF.T, origin='bottom', extent=extent, cmap='cubehelix', aspect='auto')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(224)\n",
    "    plt.title('draws')\n",
    "    # mydraws = mypdf.markov_draws(500)\n",
    "    mydraws = mypdf.markov_draws()\n",
    "\n",
    "    plt.scatter(mydraws[:, 0], mydraws[:, 1], marker='.')\n",
    "    plt.xlim((xmin, xmax))\n",
    "    plt.ylim((ymin, ymax))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    self_test()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
